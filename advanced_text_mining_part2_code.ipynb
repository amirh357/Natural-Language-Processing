{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#######################################################\n",
    "#######################################################\n",
    "############    COPYRIGHT - DATA SOCIETY   ############\n",
    "#######################################################\n",
    "#######################################################\n",
    "\n",
    "## ADVANCED TEXT MINING PART2 ##\n",
    "\n",
    "## NOTE: To run individual pieces of code, select the line of code and\n",
    "##       press ctrl + enter for PCs or command + enter for Macs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 16: Directory settings  ####\n",
    "\n",
    "from pathlib import Path\n",
    "# Set `home_dir` to the root directory of your computer.\n",
    "home_dir = Path.home()\n",
    "\n",
    "# Set `main_dir` to the location of your `booz-allen-hamilton` folder.\n",
    "main_dir = home_dir / \"Desktop\" / \"booz-allen-hamilton\"\n",
    "\n",
    "# Make `data_dir` from the `main_dir` and remainder of the path to data directory.\n",
    "data_dir = main_dir / \"data\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 17: Loading packages  ####\n",
    "\n",
    "# Helper packages.\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Packages with tools for text processing.\n",
    "import nltk\n",
    "\n",
    "# Packages for working with text data and analyzing sentiment\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Packages to build and measure the performance of a logistic regression model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 18: Working directory  ####\n",
    "\n",
    "# Set working directory.\n",
    "os.chdir(data_dir)\n",
    "# Check working directory.\n",
    "print(os.getcwd())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 20: Text classification - classify snippets  ####\n",
    "\n",
    "cleaned_txt = pickle.load(open((data_dir + '/NYT_clean_list.sav'),\"rb\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 21: Text classification - classify snippets  ####\n",
    "\n",
    "print(cleaned_txt[0:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 25: Text classification - classify (cont'd)  ####\n",
    "\n",
    "# Initialize the `SentimentIntensityAnalyzer().`\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Iterate through each sentence printing out the scores for each.\n",
    "for sentence in cleaned_txt:\n",
    "    print(sentence)\n",
    "    ss = sid.polarity_scores(sentence)\n",
    "    for k in ss:\n",
    "        print('{0}: {1}, '.format(k, ss[k]), end='')\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 27: Text classification - classify (cont'd)  ####\n",
    "\n",
    "# This function outputs a list of labels for snippet:\n",
    "def sentiment_analysis(texts):\n",
    "    list_of_scores = []\n",
    "    for text in texts:\n",
    "        sid = SentimentIntensityAnalyzer()\n",
    "        compound = sid.polarity_scores(text)[\"compound\"]\n",
    "        if compound >= 0:\n",
    "            list_of_scores.append(\"positive\")\n",
    "        else:\n",
    "            list_of_scores.append(\"negative\")\n",
    "        return(list_of_scores)\n",
    "    \n",
    "score_labels = sentiment_analysis(cleaned_txt)\n",
    "print(score_labels[1:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 28: Text classification - Load the DTM  ####\n",
    "\n",
    "DTM_matrix = pickle.load(open((data_dir + '/DTM_matrix.sav'),\"rb\"))\n",
    "DTM_array = DTM_matrix.toarray()\n",
    "\n",
    "# Let's look at the first few rows of the finalized array.\n",
    "print(DTM_array[1:4])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 33: Model building - split the dataset  ####\n",
    "\n",
    "X_train, X_test, y_train, y_test  = train_test_split(\n",
    "    DTM_array,\n",
    "    score_labels,\n",
    "    train_size = 0.70,\n",
    "    random_state = 1234)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 34: Model building - split the dataset  ####\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "print(len(y_train))\n",
    "print(len(y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 36: Exercise 1  ####\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 46: Categorical to binary target variable  ####\n",
    "\n",
    "# Initiate the Label Binarizer.\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "\n",
    "# Convert y_test to binary integer format.\n",
    "y_test= lb.fit_transform(y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 53: Logistic regression: build  ####\n",
    "\n",
    "# Set up logistic regression model.\n",
    "log_model = LogisticRegression()\n",
    "print(log_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 54: Logistic regression: fit  ####\n",
    "\n",
    "# Fit the model.\n",
    "log_model = log_model.fit(X = X_train, y = y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 56: Logistic regression: predict (cont'd)  ####\n",
    "\n",
    "# Predict on test data.\n",
    "y_pred = log_model.predict(X_test)\n",
    "print(y_pred)\n",
    "\n",
    "# Convert y_pred to binary integer format.\n",
    "y_pred= lb.fit_transform(y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 58: Exercise 2  ####\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 68: Confusion matrix and accuracy  ####\n",
    "\n",
    "# Take a look at test data confusion matrix.\n",
    "conf_matrix_test = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix_test)\n",
    "\n",
    "# Compute test model accuracy score.\n",
    "test_accuracy_score = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy on test data: \", test_accuracy_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 69: Classification report  ####\n",
    "\n",
    "# Create a list of target names to interpret class assignments.\n",
    "target_names = ['Negative', 'Positive']\n",
    "\n",
    "# Print an entire classification report.\n",
    "class_report = metrics.classification_report(y_test,\n",
    "                                             y_pred,\n",
    "                                             target_names = target_names)\n",
    "\n",
    "print(class_report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 70: Classification report (cont'd)  ####\n",
    "\n",
    "print(class_report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 71: Getting probabilities instead of class labels  ####\n",
    "\n",
    "# Get probabilities instead of predicted values.\n",
    "test_probabilities = log_model.predict_proba(X_test)\n",
    "print(test_probabilities[0:5, :])\n",
    "\n",
    "# Get probabilities of test predictions only.\n",
    "test_predictions = test_probabilities[: , 1]\n",
    "print(test_probabilities[0:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 72: Computing FPR, TPR and threshold  ####\n",
    "\n",
    "# Get FPR, TPR and threshold values.\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test,           #<- test data labels\n",
    "                                        test_predictions) #<- predicted probabilities\n",
    "\n",
    "print(\"False positive: \", fpr)\n",
    "print(\"True positive: \", tpr)\n",
    "print(\"Threshold: \", threshold)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 73: Computing AUC  ####\n",
    "\n",
    "# Get AUC by providing the FPR and TPR.\n",
    "auc = metrics.roc_auc_score(y_test,y_pred)\n",
    "print(\"Area under the ROC curve: \", auc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 74: Putting it all together: ROC plot  ####\n",
    "\n",
    "# Make an ROC curve plot.\n",
    "plt.title('Receiver Operator Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 76: Exercise 3  ####\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
