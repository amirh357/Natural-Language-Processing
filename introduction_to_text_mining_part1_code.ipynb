{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "140957c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#######################################################\n",
    "#######################################################\n",
    "############    COPYRIGHT - DATA SOCIETY   ############\n",
    "#######################################################\n",
    "#######################################################\n",
    "\n",
    "## INTRODUCTION TO TEXT MINING PART1 ##\n",
    "\n",
    "## NOTE: To run individual pieces of code, select the line of code and\n",
    "##       press ctrl + enter for PCs or command + enter for Macs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bafb4c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 15: Directory settings  ####\n",
    "\n",
    "from pathlib import Path\n",
    "# Set `home_dir` to the root directory of your computer. \n",
    "home_dir = Path.home()\n",
    "\n",
    "# Set `main_dir` to the location of your `booz-allen-hamilton` folder.\n",
    "main_dir = home_dir / \"Documents\" / \"NLP_Intro\" / \"intro-to-text-mining-main\"\n",
    "\n",
    "# Make `data_dir` from the `main_dir` and remainder of the path to data directory.\n",
    "data_dir = main_dir / \"data\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d49c81a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/amirmokhtari/Documents/NLP_Intro/intro-to-text-mining-main/data\n"
     ]
    }
   ],
   "source": [
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6acda3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/amirmokhtari/Documents/NLP_Intro/intro-to-text-mining-main/data\n"
     ]
    }
   ],
   "source": [
    "#=================================================-\n",
    "#### Slide 16: Working directory  ####\n",
    "import os\n",
    "# Set working directory.\n",
    "os.chdir(data_dir)\n",
    "\n",
    "# Check working directory.\n",
    "print(os.getcwd())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3884a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 17: Loading packages  ####\n",
    "\n",
    "# Helper packages.\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Packages with tools for text processing.\n",
    "import nltk\n",
    "import nltk.data\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c6f7b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['web_url', 'headline', 'snippet', 'word_count', 'source',\n",
      "       'type_of_material', 'date'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#=================================================-\n",
    "#### Slide 29: Loading text data  ####\n",
    "\n",
    "# Load corpus from a csv (for Mac).\n",
    "NYT = pd.read_csv('NYT_article_data.csv')\n",
    "print(NYT.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b681895",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/amirmokhtari/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b69fcb2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>web_url</th>\n",
       "      <th>headline</th>\n",
       "      <th>snippet</th>\n",
       "      <th>word_count</th>\n",
       "      <th>source</th>\n",
       "      <th>type_of_material</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.nytimes.com/reuters/2019/01/01/spo...</td>\n",
       "      <td>Pakistan Look to Fix Batting Woes Against Host...</td>\n",
       "      <td>Pakistan's struggling batsmen must find a way ...</td>\n",
       "      <td>571</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>News</td>\n",
       "      <td>2019-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.nytimes.com/reuters/2019/01/01/spo...</td>\n",
       "      <td>NFL: League Under Scrutiny for Lack of Minorit...</td>\n",
       "      <td>The National Football League is under the micr...</td>\n",
       "      <td>393</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>News</td>\n",
       "      <td>2019-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.nytimes.com/reuters/2019/01/01/spo...</td>\n",
       "      <td>Golf: Pressure On to Strike While Iron Hot Wit...</td>\n",
       "      <td>Hitting a hot streak at the right time will be...</td>\n",
       "      <td>846</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>News</td>\n",
       "      <td>2019-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.nytimes.com/aponline/2019/01/01/wo...</td>\n",
       "      <td>Papal Ode to Motherhood Ushers in 2019 After D...</td>\n",
       "      <td>Pope Francis ushered in the New Year with an o...</td>\n",
       "      <td>306</td>\n",
       "      <td>AP</td>\n",
       "      <td>News</td>\n",
       "      <td>2019-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.nytimes.com/reuters/2019/01/01/spo...</td>\n",
       "      <td>Froome, Thomas to Skip Giro d'Italia and Focus...</td>\n",
       "      <td>Chris Froome will not defend his Giro d'Italia...</td>\n",
       "      <td>265</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>News</td>\n",
       "      <td>2019-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             web_url  \\\n",
       "0  https://www.nytimes.com/reuters/2019/01/01/spo...   \n",
       "1  https://www.nytimes.com/reuters/2019/01/01/spo...   \n",
       "2  https://www.nytimes.com/reuters/2019/01/01/spo...   \n",
       "3  https://www.nytimes.com/aponline/2019/01/01/wo...   \n",
       "4  https://www.nytimes.com/reuters/2019/01/01/spo...   \n",
       "\n",
       "                                            headline  \\\n",
       "0  Pakistan Look to Fix Batting Woes Against Host...   \n",
       "1  NFL: League Under Scrutiny for Lack of Minorit...   \n",
       "2  Golf: Pressure On to Strike While Iron Hot Wit...   \n",
       "3  Papal Ode to Motherhood Ushers in 2019 After D...   \n",
       "4  Froome, Thomas to Skip Giro d'Italia and Focus...   \n",
       "\n",
       "                                             snippet  word_count   source  \\\n",
       "0  Pakistan's struggling batsmen must find a way ...         571  Reuters   \n",
       "1  The National Football League is under the micr...         393  Reuters   \n",
       "2  Hitting a hot streak at the right time will be...         846  Reuters   \n",
       "3  Pope Francis ushered in the New Year with an o...         306       AP   \n",
       "4  Chris Froome will not defend his Giro d'Italia...         265  Reuters   \n",
       "\n",
       "  type_of_material        date  \n",
       "0             News  2019-01-01  \n",
       "1             News  2019-01-01  \n",
       "2             News  2019-01-01  \n",
       "3             News  2019-01-01  \n",
       "4             News  2019-01-01  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NYT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "298706ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             web_url  \\\n",
      "0  https://www.nytimes.com/reuters/2019/01/01/spo...   \n",
      "1  https://www.nytimes.com/reuters/2019/01/01/spo...   \n",
      "2  https://www.nytimes.com/reuters/2019/01/01/spo...   \n",
      "3  https://www.nytimes.com/aponline/2019/01/01/wo...   \n",
      "4  https://www.nytimes.com/reuters/2019/01/01/spo...   \n",
      "\n",
      "                                            headline  \\\n",
      "0  Pakistan Look to Fix Batting Woes Against Host...   \n",
      "1  NFL: League Under Scrutiny for Lack of Minorit...   \n",
      "2  Golf: Pressure On to Strike While Iron Hot Wit...   \n",
      "3  Papal Ode to Motherhood Ushers in 2019 After D...   \n",
      "4  Froome, Thomas to Skip Giro d'Italia and Focus...   \n",
      "\n",
      "                                             snippet  word_count   source  \\\n",
      "0  Pakistan's struggling batsmen must find a way ...         571  Reuters   \n",
      "1  The National Football League is under the micr...         393  Reuters   \n",
      "2  Hitting a hot streak at the right time will be...         846  Reuters   \n",
      "3  Pope Francis ushered in the New Year with an o...         306       AP   \n",
      "4  Chris Froome will not defend his Giro d'Italia...         265  Reuters   \n",
      "\n",
      "  type_of_material        date  \n",
      "0             News  2019-01-01  \n",
      "1             News  2019-01-01  \n",
      "2             News  2019-01-01  \n",
      "3             News  2019-01-01  \n",
      "4             News  2019-01-01  \n"
     ]
    }
   ],
   "source": [
    "#=================================================-\n",
    "#### Slide 30: The data at first glance  ####\n",
    "\n",
    "# Look at the columns.\n",
    "print(NYT.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cd328bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     Pakistan's struggling batsmen must find a way ...\n",
      "1     The National Football League is under the micr...\n",
      "2     Hitting a hot streak at the right time will be...\n",
      "3     Pope Francis ushered in the New Year with an o...\n",
      "4     Chris Froome will not defend his Giro d'Italia...\n",
      "5     Pakistan's former Prime Minister Nawaz Sharif ...\n",
      "6     Thousands of demonstrators marched in Hong Kon...\n",
      "7     Nick Kyrgios started his Brisbane Open title d...\n",
      "8     British police confirmed on Tuesday they were ...\n",
      "9     Marcellus Wiley is still on the fence about le...\n",
      "10    Still reckoning with the fallout from her Emme...\n",
      "11    As far as Arike Ogunbowale and coach Muffet Mc...\n",
      "12    A prohibition on \"whole-home\" vacation rentals...\n",
      "13           Does contaminated food smell like freedom?\n",
      "14    There's no end in sight to the partial federal...\n",
      "Name: snippet, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#=================================================-\n",
    "#### Slide 31: Creating a list of snippets  ####\n",
    "\n",
    "# Isolate the snippet column.\n",
    "NYT_snippet = NYT[\"snippet\"]\n",
    "\n",
    "# Look at a sample of the snippet column, 0-15.\n",
    "print(NYT[\"snippet\"][0:15])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f267f7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 33: Exercise 1  ####\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17eb8340",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 42: Tokenization: split each snippet into words  ####\n",
    "\n",
    "# Tokenize each snippet into a large list of tokenized snippets.\n",
    "NYT_tokenized = [word_tokenize(NYT_snippet[i]) for i in range(0, len(NYT_snippet))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "802c4221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pakistan',\n",
       " \"'s\",\n",
       " 'struggling',\n",
       " 'batsmen',\n",
       " 'must',\n",
       " 'find',\n",
       " 'a',\n",
       " 'way',\n",
       " 'to',\n",
       " 'handle',\n",
       " 'South',\n",
       " 'Africa',\n",
       " \"'s\",\n",
       " 'potent',\n",
       " 'pace',\n",
       " 'attack',\n",
       " 'if',\n",
       " 'they',\n",
       " 'are',\n",
       " 'to',\n",
       " 'claw',\n",
       " 'their',\n",
       " 'way',\n",
       " 'back',\n",
       " 'into',\n",
       " 'the',\n",
       " 'three-match',\n",
       " 'series',\n",
       " 'in',\n",
       " 'the',\n",
       " 'second',\n",
       " 'test',\n",
       " 'that',\n",
       " 'starts',\n",
       " 'on',\n",
       " 'what',\n",
       " 'is',\n",
       " 'likely',\n",
       " 'to',\n",
       " 'be',\n",
       " 'a',\n",
       " 'lively',\n",
       " 'Newlands',\n",
       " 'wicket',\n",
       " 'on',\n",
       " 'Thursday',\n",
       " '.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NYT_tokenized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df8c333f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pakistan', \"'s\", 'struggling', 'batsmen', 'must', 'find', 'a', 'way', 'to', 'handle', 'South', 'Africa', \"'s\", 'potent', 'pace', 'attack', 'if', 'they', 'are', 'to', 'claw', 'their', 'way', 'back', 'into', 'the', 'three-match', 'series', 'in', 'the', 'second', 'test', 'that', 'starts', 'on', 'what', 'is', 'likely', 'to', 'be', 'a', 'lively', 'Newlands', 'wicket', 'on', 'Thursday', '.']\n"
     ]
    }
   ],
   "source": [
    "#=================================================-\n",
    "#### Slide 43: Save the first tokenized snippet  ####\n",
    "\n",
    "# Let's take a look at the first tokenized snippet.\n",
    "snippet_words = NYT_tokenized[0]\n",
    "print(snippet_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a353eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pakistan', \"'s\", 'struggling', 'batsmen', 'must', 'find', 'a', 'way', 'to', 'handle']\n"
     ]
    }
   ],
   "source": [
    "#=================================================-\n",
    "#### Slide 45: Convert characters to lower case  ####\n",
    "\n",
    "# 1. Convert to lower case.\n",
    "snippet_words = [word.lower() for word in snippet_words]\n",
    "print(snippet_words[:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce971243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]\n",
      "['pakistan', \"'s\", 'struggling', 'batsmen', 'must', 'find', 'way', 'handle', 'south', 'africa']\n"
     ]
    }
   ],
   "source": [
    "#=================================================-\n",
    "#### Slide 47: Remove stop words  ####\n",
    "\n",
    "# 2. Remove stop words.\n",
    "# Get common English stop words.\n",
    "stop_words = stopwords.words('english')\n",
    "print(stop_words[:10])\n",
    "\n",
    "# Remove stop words.\n",
    "snippet_words = [word for word in snippet_words if not word in stop_words]\n",
    "print(snippet_words[:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55056351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pakistan', 'struggling', 'batsmen', 'must', 'find', 'way', 'handle', 'south', 'africa', 'potent']\n"
     ]
    }
   ],
   "source": [
    "#=================================================-\n",
    "#### Slide 49: Remove non-alphabetical characters  ####\n",
    "\n",
    "# 3. Remove punctuation and any non-alphabetical characters.\n",
    "snippet_words = [word for word in snippet_words if word.isalpha()]\n",
    "# also try .isalnum()\n",
    "print(snippet_words[:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7ce5c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pakistan', 'struggl', 'batsmen', 'must', 'find', 'way', 'handl', 'south', 'africa', 'potent']\n"
     ]
    }
   ],
   "source": [
    "#=================================================-\n",
    "#### Slide 52: Stem words  ####\n",
    "\n",
    "# 4. Stem words.\n",
    "snippet_words = [PorterStemmer().stem(word) for word in snippet_words]\n",
    "print(snippet_words[:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "118ced1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(NYT_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31333e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 53: Implementing pre-processing steps on a corpus  ####\n",
    "\n",
    "# Create a list for clean snippets.\n",
    "NYT_clean = [None] * len(NYT_tokenized)\n",
    "# Create a list of word counts for each clean snippet.\n",
    "word_counts_per_snippet = [None] * len(NYT_tokenized)\n",
    "\n",
    "# Process words in all snippets.\n",
    "for i in range(len(NYT_tokenized)):\n",
    "    # 1. Convert to lower case.\n",
    "    NYT_clean[i] = [snippet.lower() for snippet in NYT_tokenized[i]]\n",
    "\n",
    "    # 2. Remove stop words.\n",
    "    NYT_clean[i] = [word for word in NYT_clean[i] if not word in stop_words]\n",
    "\n",
    "    # 3. Remove punctuation and any non-alphabetical characters.\n",
    "    NYT_clean[i] = [word for word in NYT_clean[i] if word.isalpha()]\n",
    "\n",
    "    # 4. Stem words.\n",
    "    NYT_clean[i] = [PorterStemmer().stem(word) for word in NYT_clean[i]]\n",
    "\n",
    "    # Record the word count per snippet.\n",
    "    word_counts_per_snippet[i] = len(NYT_clean[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0be448a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pakistan', 'struggl', 'batsmen', 'must', 'find', 'way', 'handl', 'south', 'africa', 'potent']\n",
      "['pakistan', 'former', 'prime', 'minist', 'nawaz', 'sharif', 'appeal', 'convict', 'prison', 'sentenc']\n",
      "['still', 'reckon', 'fallout', 'emmett', 'till', 'paint', 'chasten', 'artist', 'reveal', 'controversi']\n",
      "['bottleneck', 'offload', 'import', 'fuel', 'form', 'mexican', 'oil', 'port', 'follow', 'govern']\n",
      "['taiwanes', 'presid', 'tsai', 'appoint', 'close', 'polit', 'alli', 'premier', 'cabinet', 'reshuffl']\n"
     ]
    }
   ],
   "source": [
    "#=================================================-\n",
    "#### Slide 54: Inspect results  ####\n",
    "\n",
    "print(NYT_clean[0][:10])\n",
    "print(NYT_clean[5][:10])\n",
    "print(NYT_clean[10][:10])\n",
    "print(NYT_clean[15][:10])\n",
    "print(NYT_clean[20][:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71c354f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(word_counts_per_snippet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b805bd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24, 12, 19, 20, 19, 15, 23, 15, 22, 27]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Frequency')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#=================================================-\n",
    "#### Slide 55: Removing empty and very short snippets  ####\n",
    "\n",
    "# Let's take a look at total word counts per snippet (for the first 10). \n",
    "print(word_counts_per_snippet[:10])\n",
    "\n",
    "# Plot a histogram for word counts per snippet, set bins to number of unique values in the list. \n",
    "plt.hist(word_counts_per_snippet, bins = len(set(word_counts_per_snippet))) \n",
    "plt.xlabel('Number of words per snippet') \n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16a27149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n",
      "248\n"
     ]
    }
   ],
   "source": [
    "#=================================================-\n",
    "#### Slide 56: Removing empty and very short snippets (cont'd)  ####\n",
    "\n",
    "# Convert word counts list and snippets list to numpy arrays.\n",
    "word_counts_array = np.array(word_counts_per_snippet)\n",
    "NYT_array = np.array(NYT_clean)\n",
    "\n",
    "print(len(NYT_array))\n",
    "\n",
    "# Find indices of all snippets where there are greater than or equal to 5 words.\n",
    "valid_snippets = np.where(word_counts_array >= 5)[0]\n",
    "print(len(valid_snippets))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0f5e1889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248\n",
      "[['pakistan', 'struggl', 'batsmen', 'must', 'find', 'way', 'handl', 'south', 'africa', 'potent', 'pace', 'attack', 'claw', 'way', 'back', 'seri', 'second', 'test', 'start', 'like', 'live', 'newland', 'wicket', 'thursday'], ['nation', 'footbal', 'leagu', 'microscop', 'lack', 'minor', 'head', 'coach', 'recent', 'slew', 'fire', 'leagu'], ['hit', 'hot', 'streak', 'right', 'time', 'goal', 'golf', 'top', 'male', 'profession', 'year', 'new', 'calendar', 'cram', 'major', 'championship', 'super', 'busi', 'stretch'], ['pope', 'franci', 'usher', 'new', 'year', 'ode', 'motherhood', 'tuesday', 'remind', 'faith', 'mother', 'exampl', 'embrac', 'best', 'antidot', 'today', 'disjoint', 'world', 'solitud', 'miseri'], ['chri', 'froom', 'defend', 'giro', 'titl', 'year', 'choos', 'focu', 'win', 'fifth', 'tour', 'de', 'franc', 'crown', 'instead', 'team', 'sky', 'announc', 'tuesday']]\n"
     ]
    }
   ],
   "source": [
    "#=================================================-\n",
    "#### Slide 57: Removing empty and very short snippets (cont'd)  ####\n",
    "\n",
    "# Subset the NYT_array to keep only those where there are at least 5 words.\n",
    "NYT_array = NYT_array[valid_snippets]\n",
    "print(len(NYT_array))\n",
    "\n",
    "# Convert the array back to a list.\n",
    "NYT_clean = NYT_array.tolist()\n",
    "print(NYT_clean[:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1b8e7c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1, 2, 3, 4\n"
     ]
    }
   ],
   "source": [
    "#=================================================-\n",
    "#### Slide 58: .join() function  ####\n",
    "\n",
    "# Here is a simple example of the `.join()` function in action!\n",
    "numList = ['1', '2', '3', '4']\n",
    "print(', '.join(numList))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "021cb468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pakistan struggl batsmen must find way handl south africa potent pace attack claw way back seri second test start like live newland wicket thursday', 'nation footbal leagu microscop lack minor head coach recent slew fire leagu', 'hit hot streak right time goal golf top male profession year new calendar cram major championship super busi stretch', 'pope franci usher new year ode motherhood tuesday remind faith mother exampl embrac best antidot today disjoint world solitud miseri', 'chri froom defend giro titl year choos focu win fifth tour de franc crown instead team sky announc tuesday']\n"
     ]
    }
   ],
   "source": [
    "#=================================================-\n",
    "#### Slide 59: Save processed text to file using .join()  ####\n",
    "\n",
    "# Join words in each snippet into a single character string.\n",
    "NYT_clean_list = [' '.join(snippet) for snippet in NYT_clean]\n",
    "print(NYT_clean_list[:5])\n",
    "\n",
    "# Save output file name to a variable.\n",
    "out_filename = \"clean_NYT.txt\"\n",
    "\n",
    "# Create a function that takes a list of character strings\n",
    "# and a name of an output file and writes it into a txt file.\n",
    "def write_lines(lines, filename):    #<- given lines to write and filename\n",
    "    joined_lines = '\\n'.join(lines)  #<- join lines with line breaks\n",
    "    file = open( out_filename, 'w')  #<- open write only file\n",
    "    file.write(joined_lines)         #<- write lines to file\n",
    "    file.close()                     #<- close connection\n",
    "\n",
    "# Write sequences to file.\n",
    "write_lines(NYT_clean_list, out_filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "032f8416",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 62: Exercise 2  ####\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5115613f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "['abduct', 'abl', 'abo', 'absente', 'abus', 'academ', 'accept', 'access', 'accessori', 'accommod']\n"
     ]
    }
   ],
   "source": [
    "#=================================================-\n",
    "#### Slide 67: Create a DTM  ####\n",
    "\n",
    "# Initialize `CountVectorizer`. This library is available through scikit-learn\n",
    "vec = CountVectorizer()\n",
    "\n",
    "# Transform the list of snippets into DTM.\n",
    "X = vec.fit_transform(NYT_clean_list)\n",
    "print(X.toarray()) #<- show output as a matrix\n",
    "\n",
    "print(vec.get_feature_names()[:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e2beb6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   abduct  abl  abo  absente  abus  academ  accept  access  accessori  \\\n",
      "0       0    0    0        0     0       0       0       0          0   \n",
      "1       0    0    0        0     0       0       0       0          0   \n",
      "2       0    0    0        0     0       0       0       0          0   \n",
      "3       0    0    0        0     0       0       0       0          0   \n",
      "4       0    0    0        0     0       0       0       0          0   \n",
      "\n",
      "   accommod  ...  writer  xinhua  year  yell  yet  york  young  yuan  zimbabw  \\\n",
      "0         0  ...       0       0     0     0    0     0      0     0        0   \n",
      "1         0  ...       0       0     0     0    0     0      0     0        0   \n",
      "2         0  ...       0       0     1     0    0     0      0     0        0   \n",
      "3         0  ...       0       0     1     0    0     0      0     0        0   \n",
      "4         0  ...       0       0     1     0    0     0      0     0        0   \n",
      "\n",
      "   zykera  \n",
      "0       0  \n",
      "1       0  \n",
      "2       0  \n",
      "3       0  \n",
      "4       0  \n",
      "\n",
      "[5 rows x 1924 columns]\n"
     ]
    }
   ],
   "source": [
    "#=================================================-\n",
    "#### Slide 68: Create a DTM (cont'd)  ####\n",
    "\n",
    "# Convert the matrix into a pandas dataframe for easier manipulation.\n",
    "DTM = pd.DataFrame(X.toarray(), columns = vec.get_feature_names())\n",
    "print(DTM.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "216325d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 69: DTM to dictionary of total word counts  ####\n",
    "\n",
    "# Create a convenience function that sorts and looks at first n-entries in the dictionary.\n",
    "def HeadDict(dict_x, n):\n",
    "    # Get items from the dictionary and sort them by\n",
    "    # value key in descending (i.e. reverse) order\n",
    "    sorted_x = sorted(dict_x.items(),\n",
    "                      reverse = True,\n",
    "                      key = lambda kv: kv[1])\n",
    "\n",
    "    # Convert sorted dictionary to a list.\n",
    "    dict_x_list = list(sorted_x)\n",
    "\n",
    "    # Return the first `n` values from the dictionary only.\n",
    "    return(dict(dict_x_list[:n]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "159db2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'said': 42, 'new': 39, 'year': 32, 'presid': 29, 'friday': 22, 'govern': 22}\n"
     ]
    }
   ],
   "source": [
    "#=================================================-\n",
    "#### Slide 70: DTM to dictionary of total word counts (cont'd)  ####\n",
    "\n",
    "# Sum frequencies of each word in all documents.\n",
    "DTM.sum(axis = 0).head()\n",
    "\n",
    "# Save series as a dictionary.\n",
    "corpus_freq_dist = DTM.sum(axis = 0).to_dict()\n",
    "\n",
    "# Glance at the frequencies.\n",
    "print(HeadDict(corpus_freq_dist, 6))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d1ccd7c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "abduct     1\n",
       "abl        1\n",
       "abo        1\n",
       "absente    1\n",
       "abus       2\n",
       "          ..\n",
       "york       8\n",
       "young      5\n",
       "yuan       1\n",
       "zimbabw    1\n",
       "zykera     1\n",
       "Length: 1924, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DTM.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "87771162",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 73: Save results as a pickle  ####\n",
    "\n",
    "pickle.dump(DTM, open('DTM.sav', 'wb'))\n",
    "pickle.dump(word_counts_array, open('word_counts_array.sav', 'wb'))\n",
    "pickle.dump(NYT_clean, open('NYT_clean.sav', 'wb'))\n",
    "pickle.dump(NYT_clean_list, open('NYT_clean_list.sav', 'wb'))\n",
    "pickle.dump(corpus_freq_dist, open('corpus_freq_dist.sav', 'wb'))\n",
    "pickle.dump(X, open('DTM_matrix.sav', 'wb'))\n",
    "pickle.dump(valid_snippets, open('valid_snippets.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a920cd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================-\n",
    "#### Slide 75: Exercise 3  ####\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cc4b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
