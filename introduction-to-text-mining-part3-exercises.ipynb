{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Text Mining Part 3 - Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1\n",
    "##### Load libraries that are used in this module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2 \n",
    "##### Set `main_dir` to the location of your `booz-allen-hamilton` folder.\n",
    "##### Make `data_dir` from the `main_dir` and concatenate remainder of the path to data directory.\n",
    "##### Make `plot_dir` from the `main_dir` and concatenate remainder of the path to plots directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3 \n",
    "##### Set the working directory to `data_dir`.\n",
    "##### Check if the working directory is updated to `data_dir`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 4\n",
    "##### Load the pickled file from the previous exercises: \n",
    "\n",
    "##### 'dictionary_ex.sav', 'corpus_tfidf_ex.sav', 'bow_corpus_ex.sav', 'ex_DTM.sav' and 'ex_titles_clean.sav' and name them as\n",
    "##### 'dictionary_ex', 'corpus_tfidf_ex', 'bow_corpus_ex', 'ex_DTM' and 'processed_docs_ex'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 5 \n",
    "##### Load UN agreement titles data from original file, 'UN_agreement_titles.csv'.\n",
    "##### Load pre-saved word counts array we pickled in the previous session, `ex_word_counts_array.sav`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 6\n",
    "##### Now we are going to run LDA on our `corpus_tfidf_ex` object.\n",
    "##### Choose the same parameters as we did in the slides.\n",
    "##### Save the model as `lda_model_tfidf_ex` and print."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 7\n",
    "##### Look at the output of your LDA model, print each of the 5 topics and the top words within each topic.\n",
    "##### Then, take the first doc from `processed_docs_ex` and classify it within one of the five topics. Which one is it most similar to?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1 \n",
    "##### Find the topic coherence for the LDA model.\n",
    "##### Save it as `coherence_lda_ex` and print it out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2 \n",
    "##### Define the convenience function `compute_coherence_values` and tweak parameters as you think needed.\n",
    "##### Set the seed to 1.\n",
    "##### Compute the `model_list` and `coherence_values` using the function above.\n",
    "##### There are more titles, so maybe more topics will be necessary as a limit. Hence, set `limit` as `80`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3 \n",
    "##### Plot the findings from `model_list` and `coherence_values`.\n",
    "##### Set `x` as the range where `start` is `2`, `limit` is `80` and `step` `6`.\n",
    "##### Plot `x` against `coherence_values`. Label the axes accordingly.\n",
    "##### What would improve our LDA model? What number of topics make the most sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 4\n",
    "##### Prepare the visualization object for plotting, and assign it to a new variable 'vis'.\n",
    "###### Display the results.\n",
    "##### What can you infer about the topics by looking at this plot?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Adjust the slider from 0 to 1. What can you tell about the relevant terms in topic 3?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1 \n",
    "##### Obtain the topic probabilities for the 1st document in our corpus.\n",
    "##### Which topic has the highest probability for document 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2 \n",
    "##### Now get the best topic and its probability for the document programmatically.\n",
    "##### What is the best topic and its probability in document 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3 \n",
    "##### Define a function, GetDocTopicPair(), to extract this information for a document given an LDA model.\n",
    "\n",
    "##### Put it all together into a function that returns a tuple with the index of the document, the best fit topic, and its probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4 \n",
    "##### Apply the above function to each document in our corpus by using a loop.\n",
    "##### What does the list of tuples contain?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 5 \n",
    "##### Create a dataframe called `doc_topic_df_ex` and assign the list of tuples to it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 6 \n",
    "##### Retrieve all documents with word count less than 3 and assign original index from UN data to our `doc_topic_df_ex` dataframe.\n",
    "##### Print the last 5 rows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 7 \n",
    "##### Retrieve all documents assigned to topic 2. Save it in `topic2_docs` and output the top ten documents assigned to that topic.\n",
    "##### Print the number of documents assigned to topic 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 8 \n",
    "##### Get the indices of the top 15 documents in the topic and then the headlines of the top 15 documents in the topic from the \n",
    "##### original UN dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 9 \n",
    "##### Save the LDA visualization as a HTML file called `UN_LDAvis`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1 \n",
    "##### Generate a TDM from corpus weighted with TF-IDF, name it `TDM_tf_idf_ex`\n",
    "##### Check the dimensions of the type of the TDM.\n",
    "##### How many terms and documents are there in the 2D array?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2\n",
    "##### Convert the above TDM into a DTM called `DTM_tf_idf_ex`.\n",
    "##### Print the dimensions of the matrix.\n",
    "##### Save the matrix created as a dataframe called `DTM_df_ex`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3 \n",
    "##### Compute cosine similarity for the `DTM_tf_idf_ex` matrix.\n",
    "##### Print the shape of the matrix.\n",
    "##### Save the similarity matrix as a dataframe called `similarity_df_ex`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
