{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Text Mining Part 1 - Exercises with answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1\n",
    "##### Load libraries that are used in this module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper packages.\n",
    "import os \n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Cosine similarity and clustering packages.\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.cluster.hierarchy import ward, dendrogram, fcluster\n",
    "import gensim\n",
    "from gensim import matutils\n",
    "\n",
    "# Network creation and visualization.\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "\n",
    "# Other plotting tools.\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 2\n",
    "##### Set `main_dir` to the location of your `booz-allen-hamilton` folder.\n",
    "##### Make `data_dir` from the `main_dir` and concatenate remainder of the path to data directory.\n",
    "##### Make `plots_dir` from the `main_dir` and concatenate remainder of the path to plots directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "# Set `home_dir` to the root directory of your computer.\n",
    "home_dir = Path.home()\n",
    "\n",
    "# Set `main_dir` to the location of your `booz-allen-hamilton` folder.\n",
    "main_dir = home_dir / \"Desktop\" / \"booz-allen-hamilton\"\n",
    "\n",
    "# Make `data_dir` from the `main_dir` and remainder of the path to data directory.\n",
    "data_dir = main_dir / \"data\"\n",
    "\n",
    "# Make `plots_dir` from the `main_dir` and remainder of the path to plots directory.\n",
    "plot_dir = main_dir / \"plots\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3 \n",
    "##### Set the working directory to `data_dir`.\n",
    "##### Check if the working directory is updated to `data_dir`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the working directory.\n",
    "os.chdir(data_dir)\n",
    "\n",
    "# Check the working directory.\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 4\n",
    "##### Load the pickled file from the previous exercises: \n",
    "\n",
    "##### 'similarity_df_ex.sav', 'similarity_ex.sav', 'valid_snippets_ex.sav', 'doc_topic_df_ex.sav' and 'corpus_tfidf_ex.sav' and name them as\n",
    "##### 'similarity_df_ex', 'similarity_ex', 'valid_snippets_ex', 'doc_topic_df_ex' and 'corpus_tfidf_ex'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_df_ex = pickle.load(open('similarity_df_ex.sav', 'rb'))\n",
    "similarity_ex = pickle.load(open('similarity_ex.sav', 'rb'))\n",
    "valid_snippets_ex = pickle.load(open('valid_snippets_ex.sav', 'rb'))\n",
    "doc_topic_df_ex = pickle.load(open('doc_topic_df_ex.sav', 'rb'))\n",
    "corpus_tfidf_ex = pickle.load(open('corpus_tfidf_ex.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 5 \n",
    "##### Load UN agreement titles data from original file, 'UN_agreement_titles.csv'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UN = pd.read_csv('UN_agreement_titles.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 6\n",
    "##### Compute a graph from similarity matrix `similarity_df_ex`.\n",
    "##### Convert the graph into a dataframe in the form of a edgelist called `edgelist_df_ex`.\n",
    "##### Print the shape of `edgelist_df_ex`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a graph object from the similarity matrix.\n",
    "graph = nx.from_pandas_adjacency(similarity_df_ex)\n",
    "\n",
    "# Convert it to a dataframe in a form of an edgelist.\n",
    "edgelist_df_ex = nx.to_pandas_edgelist(graph)\n",
    "\n",
    "# Take a look at the data frame of edges.\n",
    "print(edgelist_df_ex.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(edgelist_df_ex.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 7\n",
    "##### Create a cosine similarity score distribution by plotting the weights of edges .\n",
    "##### Filter out all pairs of documents with weights below 0.4 and above 0.8.\n",
    "##### Print the head and shape of the new `edgelist_df_ex`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result:\n",
    "# Plot the weights of edges (i.e. similarity scores).\n",
    "plt.hist(edgelist_df_ex['weight'])\n",
    "plt.xlabel('Cosine similarity score')\n",
    "plt.title('Cosine similarity score distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out all entries below 0.4 and above 0.8.\n",
    "edgelist_df_ex = edgelist_df_ex.query('weight>0.4 and weight<0.8')\n",
    "\n",
    "# Take a look at the dataframe of edges.\n",
    "print(edgelist_df_ex.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(edgelist_df_ex.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 8\n",
    "##### Create an empty network object `network_ex` with the following base parameters:\n",
    "    - height - 100%\n",
    "    - width - 60%\n",
    "    - bgcolor - FFFFF\n",
    "    - font_color - 000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty network object.\n",
    "network_ex = Network(height = \"100%\",\n",
    "                     width = \"60%\",\n",
    "                     bgcolor = \"#FFFFFF\",\n",
    "                     font_color = \"#000000\")\n",
    "\n",
    "# Set the physics layout of the network.\n",
    "network_ex.force_atlas_2based()\n",
    "network_ex.set_edge_smooth('dynamic')\n",
    "print(network_ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 9\n",
    "##### Populate the empty network with edge and node data. Use `edgelift_df_ex` and \n",
    "##### zip the three necessary columns - source, target, and weight - into an iterable set of tuples.\n",
    "##### Print network nodes and network edges of your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip columns of edgelist data into a set of tuples.\n",
    "edge_data = zip(edgelist_df_ex['source'], edgelist_df_ex['target'], edgelist_df_ex['weight'])\n",
    "# Iterate through the edge data.\n",
    "for e in edge_data:\n",
    "    src = e[0] #<- get the source node\n",
    "    dst = e[1] #<- get the destination (i.e. target node)\n",
    "    w = e[2] #<- get the weight of the edge\n",
    "# Add a source node with its information.\n",
    "    network_ex.add_node(src, src, title = src)\n",
    "# Add a destination node with its information.\n",
    "    network_ex.add_node(dst, dst, title = dst)\n",
    "# Add an edge between source and destination nodes with weight w.\n",
    "    network_ex.add_edge(src, dst, value = w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(network_ex.nodes[0:5])\n",
    "print(network_ex.edges[0:5])\n",
    "print(network_ex.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 10\n",
    "##### Get the neighbor map for each node.\n",
    "##### Print the document IDs that are most similar to document 25."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of node neighbors.\n",
    "neighbor_map = network_ex.get_adj_list()\n",
    "\n",
    "# Show documents most similar to document 25.\n",
    "print(neighbor_map[25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 11\n",
    "##### Add the neighbor node information into the hover over tooltip.\n",
    "##### Print information for node 5.\n",
    "##### Save the network graph as `UN_similar_snippets` and show it in browser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add neighbor data to node hover data.\n",
    "for node in network_ex.nodes:\n",
    "    title = \"Most similar articles: <br>\"\n",
    "    neighbors = list(neighbor_map[node[\"id\"]])\n",
    "    title = title + \"<br>\".join(str(neighbor) for neighbor in neighbors)\n",
    "    node[\"title\"] = title\n",
    "\n",
    "print(network_ex.nodes[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save html and show graph in browser.\n",
    "network_ex.show(plot_dir + \"/UN_similar_snippets.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 12\n",
    "##### Hover over a node of your choice to see the list of all its neighbors. For example, node 924 is used below.\n",
    "##### Print the articles from the edgelist `edgelist_df_ex` with their weights.\n",
    "##### Look up the articles closest to the node and print them.\n",
    "##### Modify the graph's appearance by using `physics` parameter and re-save the graph.\n",
    "##### Optional: Try using `nodes` and `edges` parameters to change the appearance of the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgelist_df_subset_ex = edgelist_df_ex.query(\"source==924\")\n",
    "print(edgelist_df_subset_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(edgelist_df_subset_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(UN.iloc[924, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(UN.iloc[450, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(UN.iloc[914, 0])\n",
    "# We can see that these 3 articles are similar, because their snippets all start and end the same way: Development Credit Agreement..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show buttons to modify the look.\n",
    "network_ex.show_buttons(filter_=['physics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save html and show graph in browser.\n",
    "network_ex.show(plot_dir+\"/UN_similar_snippets.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1 \n",
    "##### Compute the distance matrix `distance_ex` from `similarity_ex`.\n",
    "##### Create the linkage matrix based on `distance_ex` and print the first 10 rows.\n",
    "##### Print the shape of the matrix and the first 4 links.\n",
    "##### Print the 110th link. Which clusters are linked? What is the distance between them? How many observations are there in the new cluster?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute distance matrix by subtracting similarity from 1.\n",
    "distance_ex = 1 - similarity_ex\n",
    "\n",
    "# Define the `linkage_matrix` using `ward` clustering algorithm.\n",
    "linkage_matrix_ex = ward(distance_ex)\n",
    "print(linkage_matrix_ex[0:10])\n",
    "\n",
    "# Print shape of the matrix.\n",
    "print(linkage_matrix_ex.shape)\n",
    "    \n",
    "print(linkage_matrix_ex[0:4])\n",
    "\n",
    "#Print the 110th link in the matrix.\n",
    "print(linkage_matrix_ex[109])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`110th link` was between clusters `426` and `1050`, with distance of `0` and the number of observations in the new cluster being `3`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2 \n",
    "##### Visualize the hierarchical clusters with right orientation and leaf font size 14. Set figsize to (15, 40).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can plot the hierarchical clusters.\n",
    "fig, axes = plt.subplots(figsize = (15, 40))\n",
    "axes = dendrogram(linkage_matrix_ex,\n",
    "                  orientation = \"right\",\n",
    "                  labels = valid_snippets_ex,\n",
    "                  leaf_font_size = 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3 \n",
    "##### Split the dendrogram based on maximum clusters. Set the maximum number of clusters named `k` as 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set k - the max number of clusters.\n",
    "k = 3\n",
    "\n",
    "# Get cluster labels for each snippet.\n",
    "cluster_labels = fcluster(linkage_matrix_ex, #<- linkage matrix\n",
    "                          k, #<- max number of clusters\n",
    "                          criterion = 'maxclust') #<- criterion maxclust\n",
    "print(cluster_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4 \n",
    "##### Create a variable with valid snippets of `UN` and name as ` UN_valid_articles`.\n",
    "##### Add `cluster_labels` to `UN_valid_articles` and name the column as `hclust_label`.\n",
    "##### Sort `doc_topic_df_ex` by `doc_id` and save.\n",
    "##### Add a column called `LDA_topic_label` to `UN_valid_articles` from `best_topic` in `doc_topic_df_ex`.\n",
    "##### Save the plot and the data in png and csv format respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UN_valid_articles = UN.loc[valid_snippets_ex]\n",
    "UN_valid_articles['hclust_label'] = cluster_labels\n",
    "doc_topic_df_ex = doc_topic_df_ex.sort_values(by = \"doc_id\")\n",
    "UN_valid_articles['LDA_topic_label'] = doc_topic_df_ex['best_topic']\n",
    "\n",
    "fig.savefig(plot_dir + '/UN_hclust.png')\n",
    "UN_valid_articles.to_csv(data_dir + '/UN_snippets_with_cluster_labels.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
