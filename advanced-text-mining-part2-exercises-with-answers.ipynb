{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Text Mining Part 2 - Exercises with Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following exercises, we will work with data from movie reviews for the sentiment analysis. The movie reviews were scraped from a website. Each review is a document and, collectively, the reviews form the corpus. We will be using the `movie_reviews.csv` file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1\n",
    "##### Load the following packages/libraries that are used in this module:\n",
    "##### pandas, numpy, pickle (Helper packages); nltk (natural language toolkit for text processing); scikit-learn; matplotlib (for visualizing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T15:04:42.785250Z",
     "start_time": "2020-06-22T15:04:41.081119Z"
    }
   },
   "outputs": [],
   "source": [
    "# Helper packages.\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Packages with tools for text processing.\n",
    "import nltk\n",
    "\n",
    "# Packages for working with text data and analyzing sentiment.\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Packages to build and measure the performance of a logistic regression model. \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Package for visualizing the results.\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 2\n",
    "##### Set `main_dir` to the location of your `booz-allen-hamilton` folder.\n",
    "##### Make `data_dir` from the `main_dir` and concatenate remainder of the path to data directory.\n",
    "##### Make `plots_dir` from the `main_dir` and concatenate remainder of the path to plots directory.\n",
    "##### Set the working directory to `data_dir`.\n",
    "##### Check if the working directory is updated to `data_dir`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "# Set `home_dir` to the root directory of your computer.\n",
    "home_dir = Path.home()\n",
    "\n",
    "# Set `main_dir` to the location of your `booz-allen-hamilton` folder.\n",
    "main_dir = home_dir / \"Desktop\" / \"booz-allen-hamilton\"\n",
    "\n",
    "# Make `data_dir` from the `main_dir` and remainder of the path to data directory.\n",
    "data_dir = main_dir / \"data\"\n",
    "\n",
    "# Make `plots_dir` from the `main_dir` and remainder of the path to plots directory.\n",
    "plot_dir = main_dir / \"plots\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T15:05:04.300064Z",
     "start_time": "2020-06-22T15:05:04.292503Z"
    }
   },
   "outputs": [],
   "source": [
    "# Change the working directory.\n",
    "os.chdir(data_dir)\n",
    "\n",
    "# Check the working directory.\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3\n",
    "\n",
    "###### Load the `movie_reviews.csv` file and preview the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_reviews = pd.read_csv('movie_reviews.csv')\n",
    "movie_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4\n",
    "##### Execute the below chuck of code that performs the following steps in order to clean the movie reviews data. (These are the same steps that were used to preprocess the text data in our earlier module)\n",
    "\n",
    "##### 1. Converted all characters to lower case \n",
    "##### 2. Removed stop words \n",
    "##### 3. Removed punctuation, numbers, and all other symbols that are not letters \n",
    "##### 4. Stemmed words\n",
    "##### 5. Saved the cleaned reviews in the list `reviews_clean_list` and created a Document-Term Matrix and saved it as `reviews_DTM` \n",
    "\n",
    "###### Print the first 10 reviews from `reviews_clean_list`.\n",
    "\n",
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = movie_reviews[\"reviews\"]\n",
    "\n",
    "reviews_tokenized = [word_tokenize(reviews[i]) for i in range(0,len(reviews))]\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# Create a vector for clean reviews.\n",
    "reviews_clean = [None] * len(reviews_tokenized)\n",
    "# Create a vector of word counts for each clean reviews.\n",
    "word_counts_per_reviews = [None] * len(reviews_tokenized)\n",
    "# Process words in all documents.\n",
    "for i in range(len(reviews_tokenized)):\n",
    "    # 1. Convert to lower case.\n",
    "    reviews_clean[i] = [reviews.lower() for reviews in reviews_tokenized[i]]\n",
    "    \n",
    "    # 2. Remove stopwords.\n",
    "    reviews_clean[i] = [word for word in reviews_clean[i] if not word in stop_words]\n",
    "    \n",
    "    # 3. Remove punctuation and any non-alphabetical characters.\n",
    "    reviews_clean[i] = [word for word in reviews_clean[i] if word.isalpha()]\n",
    "    \n",
    "    # 4. Stem words.\n",
    "    reviews_clean[i] = [PorterStemmer().stem(word) for word in reviews_clean[i]]\n",
    "    \n",
    "    # Record the word count per reviews.\n",
    "    word_counts_per_reviews[i] = len(reviews_clean[i])\n",
    "reviews_clean_list = [' '.join(message) for message in reviews_clean]\n",
    "\n",
    "ex_vec = CountVectorizer()\n",
    "ex_X = ex_vec.fit_transform(reviews_clean_list)\n",
    "\n",
    "reviews_DTM = pd.DataFrame(ex_X.toarray(), columns = ex_vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reviews_clean_list[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 5\n",
    "##### We want to analyze the sentiment of the movie reviews.\n",
    "##### Let us first add the sentiment labels to our cleaned reviews.\n",
    "##### Load the sentiment analysis function we used in our module.\n",
    "\n",
    "##### This function outputs a list of labels for each chat message:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T15:05:06.580778Z",
     "start_time": "2020-06-22T15:05:06.573117Z"
    }
   },
   "outputs": [],
   "source": [
    "def sentiment_analysis(texts):\n",
    "    list_of_scores = []\n",
    "    for text in texts:\n",
    "        sid = SentimentIntensityAnalyzer()\n",
    "        compound = sid.polarity_scores(text)[\"compound\"]\n",
    "        if compound >= 0:\n",
    "            list_of_scores.append(\"positive\")\n",
    "        else:\n",
    "            list_of_scores.append(\"negative\")\n",
    "    return(list_of_scores) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Assign labels to the `reviews_clean_list` using the `sentiment_analysis` function and save to them to `score_labels` variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T15:05:10.254753Z",
     "start_time": "2020-06-22T15:05:07.696595Z"
    }
   },
   "outputs": [],
   "source": [
    "score_labels = sentiment_analysis(reviews_clean_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 6\n",
    "##### Split the `reviews_DTM` dataset to 70% training and 30% test sets.\n",
    "##### Split `score_labels` the same way too.\n",
    "##### Use random state 2.\n",
    "##### Let the output variables be named the same way we named them in class:\n",
    " - `X_train`\n",
    " - `X_test`\n",
    " - `y_train`\n",
    " - `y_test`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T15:05:10.295027Z",
     "start_time": "2020-06-22T15:05:10.287194Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(reviews_DTM, \n",
    "                                                    score_labels, \n",
    "                                                    train_size = 0.70,\n",
    "                                                    random_state = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1\n",
    "##### Use LabelBinarizer function from the preprocessing module to convert categorical variables to binary target variables in `y_test`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T15:05:11.122175Z",
     "start_time": "2020-06-22T15:05:11.115632Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initiate the Label Binarizer.\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "\n",
    "# Convert y_test to binary integer format.\n",
    "y_test= lb.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2\n",
    "##### Build the logistic regression model and save it as `log_model` variable, then inspect it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T15:05:12.140017Z",
     "start_time": "2020-06-22T15:05:12.130499Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set up logistic regression model.\n",
    "log_model = LogisticRegression(solver='liblinear')\n",
    "print(log_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3\n",
    "##### Fit the model to `X_train` and `y_train` data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T15:05:12.809503Z",
     "start_time": "2020-06-22T15:05:12.795043Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fit the model.\n",
    "log_model = log_model.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4 \n",
    "##### Use the model and predict on the test dataset.\n",
    "##### Save the predictions to `y_pred` variable.\n",
    "##### Convert the categorical `y_pred` values to binary values using Label Binarizer.\n",
    "##### Print the first 5 values of `y_pred`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T15:05:13.377651Z",
     "start_time": "2020-06-22T15:05:13.362081Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict on test data.\n",
    "y_pred = log_model.predict(X_test)\n",
    "print(y_pred)\n",
    "\n",
    "# Convert y_pred to binary integer format.\n",
    "y_pred= lb.fit_transform(y_pred)\n",
    "print(y_pred[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1\n",
    "##### Print the confusion matrix and accuracy on the test data.\n",
    "##### Interpret the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T15:05:14.129418Z",
     "start_time": "2020-06-22T15:05:14.118146Z"
    }
   },
   "outputs": [],
   "source": [
    "# Take a look at test data confusion matrix.\n",
    "conf_matrix_test = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix_test)\n",
    "\n",
    "# Compute test model accuracy score.\n",
    "test_accuracy_score = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy on test data: \", test_accuracy_score)\n",
    "\n",
    "# The model predicts the sentiment of the reviews with about 90% accuracy.\n",
    "# It predicts the positive reviews better than the negative reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2\n",
    "##### Print the classification report by making the target variable classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T15:05:15.489441Z",
     "start_time": "2020-06-22T15:05:15.474019Z"
    }
   },
   "outputs": [],
   "source": [
    "# Result:\n",
    "# Create a list of target names to interpret class assignments.\n",
    "target_names = ['Negative', 'Positive']\n",
    "\n",
    "# Print an entire classification report.\n",
    "class_report = metrics.classification_report(y_test, y_pred, target_names = target_names)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3\n",
    "##### Print the probabilities of classifying the reviews as positive/negative.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T15:05:16.247232Z",
     "start_time": "2020-06-22T15:05:16.237131Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get probabilities instead of predicted values.\n",
    "test_probabilities = log_model.predict_proba(X_test)\n",
    "print(test_probabilities[0:5, :])\n",
    "\n",
    "# Get probabilities of test predictions only.\n",
    "test_predictions = test_probabilities[: , 1]\n",
    "print(test_probabilities[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4\n",
    "##### Get TPR, FPR and threshold values.\n",
    "#### Inspect the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T15:05:16.963843Z",
     "start_time": "2020-06-22T15:05:16.954702Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get FPR, TPR and threshold values.\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, test_predictions)\n",
    "print(\"False positive: \", fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 5\n",
    "#####  Compute the AUC and print it.\n",
    "##### Plot the ROC curve.\n",
    "##### Interpret the results.\n",
    "##### Why do you think we have such results?\n",
    "##### What could we do to improve our model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T15:05:17.936026Z",
     "start_time": "2020-06-22T15:05:17.683884Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get AUC by providing the FPR and TPR.\n",
    "auc = metrics.roc_auc_score(y_test, y_pred)\n",
    "print(\"Area under the ROC curve: \", auc)\n",
    "\n",
    "# Make an ROC curve plot.\n",
    "plt.title('Receiver Operator Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "# We get a fairly poor model, because of a few reasons:\n",
    "# - Small dataset with relatively few datapoints\n",
    "# - Unbalanced dataset with the majority of observations being positive and few negative\n",
    "# - Untuned model\n",
    "\n",
    "# We could improve our model by:\n",
    "# - Getting more datapoints (i.e. scraping more reviews or getting our hands on a movie review database)\n",
    "# - Removing some positive reviews or adding more negative reviews (or even generating some negative reviews!)\n",
    "# - Tuning the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
