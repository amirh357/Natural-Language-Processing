{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Text Mining Part 2 - Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following exercises, we will work with data from movie reviews for the sentiment analysis. The movie reviews were scraped from a website. Each review is a document and, collectively, the reviews form the corpus. We will be using the `movie_reviews.csv` file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1\n",
    "##### Load the following packages/libraries that are used in this module:\n",
    "##### pandas, numpy, pickle (Helper packages); nltk (natural language toolkit for text processing); scikit-learn; matplotlib (for visualizing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 2\n",
    "##### Set `main_dir` to the location of your `booz-allen-hamilton` folder.\n",
    "##### Make `data_dir` from the `main_dir` and concatenate remainder of the path to data directory.\n",
    "##### Make `plots_dir` from the `main_dir` and concatenate remainder of the path to plots directory.\n",
    "##### Set the working directory to `data_dir`.\n",
    "##### Check if the working directory is updated to `data_dir`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3\n",
    "\n",
    "###### Load the `movie_reviews.csv` file and preview the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4\n",
    "##### Execute the below chuck of code that performs the following steps in order to clean the movie reviews data. (These are the same steps that were used to preprocess the text data in our earlier module)\n",
    "\n",
    "##### 1. Converted all characters to lower case \n",
    "##### 2. Removed stop words \n",
    "##### 3. Removed punctuation, numbers, and all other symbols that are not letters \n",
    "##### 4. Stemmed words\n",
    "##### 5. Saved the cleaned reviews in the list `reviews_clean_list` and created a Document-Term Matrix and saved it as `reviews_DTM` \n",
    "\n",
    "###### Print the first 10 reviews from `reviews_clean_list`.\n",
    "\n",
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 5\n",
    "##### We want to analyze the sentiment of the movie reviews.\n",
    "##### Let us first add the sentiment labels to our cleaned reviews.\n",
    "##### Load the sentiment analysis function we used in our module.\n",
    "\n",
    "##### This function outputs a list of labels for each chat message:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T15:05:06.580778Z",
     "start_time": "2020-06-22T15:05:06.573117Z"
    }
   },
   "outputs": [],
   "source": [
    "def sentiment_analysis(texts):\n",
    "    list_of_scores = []\n",
    "    for text in texts:\n",
    "        sid = SentimentIntensityAnalyzer()\n",
    "        compound = sid.polarity_scores(text)[\"compound\"]\n",
    "        if compound >= 0:\n",
    "            list_of_scores.append(\"positive\")\n",
    "        else:\n",
    "            list_of_scores.append(\"negative\")\n",
    "    return(list_of_scores) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Assign labels to the `reviews_clean_list` using the `sentiment_analysis` function and save to them to `score_labels` variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 6\n",
    "##### Split the `reviews_DTM` dataset to 70% training and 30% test sets.\n",
    "##### Split `score_labels` the same way too.\n",
    "##### Use random state 2.\n",
    "##### Let the output variables be named the same way we named them in class:\n",
    " - `X_train`\n",
    " - `X_test`\n",
    " - `y_train`\n",
    " - `y_test`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1\n",
    "##### Use LabelBinarizer function from the preprocessing module to convert categorical variables to binary target variables in `y_test`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2\n",
    "##### Build the logistic regression model and save it as `log_model` variable, then inspect it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3\n",
    "##### Fit the model to `X_train` and `y_train` data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4 \n",
    "##### Use the model and predict on the test dataset.\n",
    "##### Save the predictions to `y_pred` variable.\n",
    "##### Convert the categorical `y_pred` values to binary values using Label Binarizer.\n",
    "##### Print the first 5 values of `y_pred`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1\n",
    "##### Print the confusion matrix and accuracy on the test data.\n",
    "##### Interpret the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2\n",
    "##### Print the classification report by making the target variable classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3\n",
    "##### Print the probabilities of classifying the reviews as positive/negative.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4\n",
    "##### Get TPR, FPR and threshold values.\n",
    "#### Inspect the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 5\n",
    "#####  Compute the AUC and print it.\n",
    "##### Plot the ROC curve.\n",
    "##### Interpret the results.\n",
    "##### Why do you think we have such results?\n",
    "##### What could we do to improve our model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
